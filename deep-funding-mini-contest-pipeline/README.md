# deep-funding-mini-contest-pipeline

End-to-end workflow for our **Deep Funding mini-contest** entry on the Pond platform (model page ğŸ”—: [https://cryptopond.xyz/modelfactory/detail/306250](https://cryptopond.xyz/modelfactory/detail/306250)).
The code pulls public OSS metrics, builds rich feature sets, trains a stacked model, emits a submission CSV **and** ships two visual layers:

1. A **UMAP viewer dataset** (`6_umap.py`) used in our write-up ([https://research.allo.capital/t/submission-of-entries-to-the-deep-funding-mini-contest/22/11](https://research.allo.capital/t/submission-of-entries-to-the-deep-funding-mini-contest/22/11)).
2. A **local Shiny dashboard** (`app.R`) that lets you explore the same data interactively.

Everything below reflects the actual codeâ€”no extra features are described.

---

## 1 Â· Solution at a glance

| Phase               | What happens                                                                                              |
| ------------------- | --------------------------------------------------------------------------------------------------------- |
| **Data collection** | GitHub REST + OSO BigQuery metrics for every repo in *train âˆª test*.                                      |
| **Embeddings**      | Shallow-clone each repo, embed docs with **Ollama / nomic-embed-text**.                                   |
| **Features**        | >1 000 engineered features: ratios, logs, one-hots, embedding slices.                                     |
| **Model**           | Stacked ensemble (XGB + RF + GB + SVR â†’ XGB meta-learner) predicting `weight_a`.                          |
| **Visuals**         | `6_umap.py` builds `UMAPData.csv`; `app.R` renders an interactive UMAP plot with percentile highlighting. |

Compliance âœ“: no external funding labelsâ€”only public metadata and embeddings feed the model.

---

## 2 Â· Repository layout

| File                        | Purpose                                                                        |
| --------------------------- | ------------------------------------------------------------------------------ |
| `0_get_github_stats_oso.py` | Query OSO BigQuery â†’ `repostatsoso_df.csv`.                                    |
| `1_get_github_stats.py`     | GitHub REST API â†’ `repostats_df.csv`.                                          |
| `2_get_github_repo.py`      | Clone + embed â†’ `repoemb_df.csv`.                                              |
| `3_create_features.py`      | Merge & engineer features â†’ `trainfeatures.csv`, `testfeatures.csv`.           |
| `5_fit_model.py`            | Train stacked model â†’ **`sub_stacked.csv`** (contest submission).              |
| `6_umap.py`                 | Build **`HuggingFaceData/UMAPData.csv`** (input for external UMAP demo).       |
| **`app.R`**                 | Shiny dashboard for local interactive exploration of **`FundingMapData.csv`**. |

### Generated folders

```
CryptoPondData/
â”œâ”€â”€ dataset.csv               â† contest train pairs (add manually)
â”œâ”€â”€ test.csv                  â† contest test  pairs (add manually)
â”œâ”€â”€ repos/                    â† git clones
â”œâ”€â”€ repostats/                â† GitHub API JSON
â”œâ”€â”€ repostats_df.csv
â”œâ”€â”€ repostatsoso_df.csv
â”œâ”€â”€ repoemb_df.csv
â”œâ”€â”€ trainfeatures.csv
â”œâ”€â”€ testfeatures.csv
â””â”€â”€ sub_stacked.csv
HuggingFaceData/
â””â”€â”€ UMAPData.csv              â† via 6_umap.py
shiny/
â””â”€â”€ www/server_Icon1.png      â† logo used by app.R (create folder if absent)
```

---

## 3 Â· Quick-start (Python pipeline)

```bash
# 1 Â· Install Python deps
pip install -r requirements.txt
#    (needs git, ollama running on :9000, and gcloud SDK or a BigQuery
#     service-account JSON for OSO queries)

# 2 Â· Credentials
export GITHUB_TOKEN=ghp_yourtoken
export GOOGLE_APPLICATION_CREDENTIALS=oso_gcp_credentials.json

# 3 Â· Run end-to-end
python 0_get_github_stats_oso.py
python 1_get_github_stats.py
python 2_get_github_repo.py
python 3_create_features.py
python 5_fit_model.py        # â†’ CryptoPondData/sub_stacked.csv

# 4 Â· (Optional) build the UMAP dataset for external demo
python 6_umap.py             # â†’ HuggingFaceData/UMAPData.csv
```

---

## 4 Â· Shiny dashboard (`app.R`)

### What it does

* Loads **`FundingMapData.csv`** (same shape as `UMAPData.csv` but named for the app).
* Lets you choose **any two numeric columns** (defaults `UMAP1/UMAP2`) for the axes.
* Lets you highlight points above/below a selectable **percentile range** on a third metric.
* Uses **ggplot2 + plotly** for an interactive scatter; hovering shows repo name & the chosen metric value.
* Overlays a logo image (`www/server_Icon1.png`) in the bottom-right corner of the plot.

### Run it

```bash
# Install R packages once
R -e "install.packages(c('shiny','ggplot2','dplyr','plotly','RCurl'))"

# Ensure dataset & logo exist:
#   FundingMapData.csv             â† in the same working directory as app.R
#   shiny/www/server_Icon1.png     â† create this path and drop your PNG

# Launch the app
R -e "shiny::runApp('app.R', launch.browser = TRUE)"
```

### File expectations

* **`FundingMapData.csv`** must contain at least the columns referenced in the code:
  `SumWeights`, `UMAP1`, `UMAP2`, `Size`, `StarCount`, `Forks`, `IssueCount`.
  (You can symlink or copy `HuggingFaceData/UMAPData.csv` if you prefer.)
* **Logo**: any 100 Ã— 100 px PNG is fine; the app base-64 encodes it for Plotly.

---

## 5 Â· UMAP dataset builder (`6_umap.py`)

1. Enumerates every distinct repo in train âˆª test.
2. Creates all pairwise feature rows and scores them with the trained XGB backbone.
3. Sums predicted weights per repo (`SumWeights`) and appends to embeddings.
4. Writes `HuggingFaceData/UMAPData.csv`â€”ready for Shiny, HF Spaces, or any UMAP/TSNE viewer.

---

## 6 Â· Model highlights

* **Transitivity-safe**: per-repo scoring â†’ derive pairwise weights, so `A<B<B<C â‡’ A<C`.
* **Rich features**: ratios (A/B), logs, categorical encodings, embedding slices.
* **Stacked ensemble** consistently beats single models in 5-fold CV (MSE).
* **Reproducible**: cached artefacts allow fast re-runs; scripts are idempotent.

For further discussion, ablation tables, and leaderboard scores, see the forum write-up.

